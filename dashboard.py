# import pandas as pd
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import plotly.figure_factory as ff
from plotly.subplots import make_subplots
from collections import Counter
from typing import List
import math

dataset_url = "https://raw.githubusercontent.com/frankcholula/flow-disability-employment/main/data/scores.csv"

# å…§åœ¨æŒ‡æ¨™ + å¤–åœ¨æŒ‡æ¨™
inside_features = ["å·¥ä½œæ„é¡˜å’Œå‹•æ©Ÿ", "å­¸ç¿’å‹•åŠ›", "åŸºæœ¬æºé€šè¡¨é”", "å·¥ä½œè²¬ä»»æ„Ÿ", "è§£æ±ºå•é¡Œæ„é¡˜"]
outside_features = ["ç¤¾ç¾¤å’Œç¤¾äº¤æ´»å‹•", "è‡ªæˆ‘èº«å¿ƒç…§é¡§", "å®¶äººæ”¯æŒç¨‹åº¦", "ç§äººä¼æ¥­å·¥ä½œç¶“é©—", "é‡åŒ–æ±‚è·è€ƒé‡", "å…ˆå¤©å¾Œå¤©"]
meta_features = ["å—è¨ªè€…", "å…§å¤–éƒ¨", "é—œéµTA"]
target = "é—œéµTA"

# page setup
st.set_page_config(
    page_title="è‹¥æ°´èº«éšœå°±æ¥­è³‡æ–™åˆ†æ",
    page_icon="ğŸš°",
    layout="wide",
)


# data preparation
@st.cache_data
def read_data(file_path) -> pd.DataFrame:
    """
    Read data from csv file and return 3 dataframes
    """
    scores_df = pd.read_csv(file_path)
    return scores_df


class Visualization:
    """_summary_"""

    def __init__(self, vis, *args):
        self.vis = vis
        dispatcher = {
            "personality": self.generate_all_radar_charts,
            "distribution": self.generate_distribution,
            "median": self.generate_median_radar_chart,
            "correlation": self.generate_correlation_matrix,
            "disability": self.generate_disability_histogram,
            "education": self.generate_education_histogram,
            "job_consideration": self.generate_job_consideration_histogram,
            "job_channel": self.generate_job_channel_histogram,
        }

        init_func = dispatcher.get(vis)
        if not init_func:
            raise ValueError(f"Uknown visualization type: {vis}")
        else:
            init_func(*args)

    def generate_median_radar_chart(self, df, features):
        def get_median_df(df):
            try:
                if df["é—œéµTA"].unique()[0] == "T":
                    key = "é—œéµTAä¸­é–“å€¼"
                else:
                    key = "éé—œéµTAä¸­é–“å€¼"
                key = "å¤–éƒ¨" + key if df["å…§å¤–éƒ¨"].unique()[0] == "å¤–éƒ¨" else "å…§éƒ¨" + key
                avg_inside_features = df[inside_features].median()
                avg_outside_features = df[outside_features].median()
                avg_ta = pd.Series(
                    [key]
                    + [None] * (len(meta_features) - 1)
                    + avg_inside_features.tolist()
                    + avg_outside_features.tolist()
                    + [key],
                    index=["å—è¨ªè€…"]
                    + meta_features[1:]
                    + inside_features
                    + outside_features
                    + [target],
                )
            except Exception as e:
                avg_ta = pd.Series([0.0] * len(df.columns), index=df.columns)
            return avg_ta.to_frame().transpose()

        median_col1, median_col2 = st.columns(2)
        with median_col1:
            inside_outside_filter = st.selectbox("é¸æ“‡å…§å¤–éƒ¨", pd.unique(df["å…§å¤–éƒ¨"]))
        df = df[df["å…§å¤–éƒ¨"] == inside_outside_filter].reset_index(drop=True)
        if inside_outside_filter == "å¤–éƒ¨":
            with median_col2:
                ta_filter = st.selectbox("é¸æ“‡é—œéµTA", pd.unique(scores_df["é—œéµTA"]))
            df = df[df["é—œéµTA"] == ta_filter].reset_index(drop=True)
        st.markdown("### å…­å¤§æŒ‡æ¨™ä¸­é–“å€¼")
        metrics = get_median_df(df)
        is1, is2, is3, is4, is5, is6 = st.columns(6)
        is1.metric("å·¥ä½œæ„é¡˜å’Œå‹•æ©Ÿ", int(metrics["å·¥ä½œæ„é¡˜å’Œå‹•æ©Ÿ"].values[0]))
        is2.metric("å­¸ç¿’å‹•åŠ›", int(metrics["å­¸ç¿’å‹•åŠ›"].values[0]))
        is3.metric("åŸºæœ¬æºé€šè¡¨é”", int(metrics["åŸºæœ¬æºé€šè¡¨é”"].values[0]))
        is4.metric("å·¥ä½œè²¬ä»»æ„Ÿ", int(metrics["å·¥ä½œè²¬ä»»æ„Ÿ"].values[0]))
        is5.metric("è§£æ±ºå•é¡Œæ„é¡˜", int(metrics["è§£æ±ºå•é¡Œæ„é¡˜"].values[0]))
        is6.metric("è‡ªæˆ‘èº«å¿ƒç…§é¡§", int(metrics["è‡ªæˆ‘èº«å¿ƒç…§é¡§"].values[0]))
        self.generate_all_radar_charts(metrics, radar_features, 1, 0, 1)

    def generate_all_radar_charts(
        self,
        df,
        features,
        charts_per_row,
        vertical_spacing=0.07,
        horizontal_spacing=0.6,
    ):
        MAX_VALUES = {
            "å·¥ä½œæ„é¡˜å’Œå‹•æ©Ÿ": 5,
            "å­¸ç¿’å‹•åŠ›": 3,
            "åŸºæœ¬æºé€šè¡¨é”": 3,
            "å·¥ä½œè²¬ä»»æ„Ÿ": 3,
            "è§£æ±ºå•é¡Œæ„é¡˜": 3,
            "ç¤¾ç¾¤å’Œç¤¾äº¤æ´»å‹•": 3,
            "å®¶äººæ”¯æŒç¨‹åº¦": 5,
            "ç§äººä¼æ¥­å·¥ä½œç¶“é©—": 1,
            "é‡åŒ–æ±‚è·è€ƒé‡": 3,
            "å…ˆå¤©å¾Œå¤©": 1,
            "è‡ªæˆ‘èº«å¿ƒç…§é¡§": 6,
        }
        n_rows = math.ceil(len(df) / charts_per_row)
        features_closed = features + [features[0]]

        # Create a subplot layout
        if charts_per_row > 1:
            fig = self._generate_multiple_charts(
                df,
                features,
                features_closed,
                charts_per_row,
                n_rows,
                MAX_VALUES,
                vertical_spacing,
                horizontal_spacing,
            )
        else:
            fig = self._generate_single_chart(df, features, features_closed, MAX_VALUES)

        st.plotly_chart(fig, use_container_width=True)

    def _generate_multiple_charts(
        self,
        df,
        features,
        features_closed,
        charts_per_row,
        n_rows,
        MAX_VALUES,
        vertical_spacing,
        horizontal_spacing,
    ):
        fig = make_subplots(
            rows=n_rows,
            cols=charts_per_row,
            specs=[[{"type": "polar"}] * charts_per_row] * n_rows,
            subplot_titles=(df.å—è¨ªè€…),
            vertical_spacing=vertical_spacing,
            horizontal_spacing=horizontal_spacing,
        )

        layout_update = {}

        for index, row in df.iterrows():
            row_normalized = {col: row[col] / MAX_VALUES[col] for col in features}
            row_normalized_list = list(row_normalized.values()) + [
                list(row_normalized.values())[0]
            ]

            subplot_row = index // charts_per_row + 1
            subplot_col = index % charts_per_row + 1
            polar_name = f"polar{index+1}"
            layout_update[polar_name] = dict(radialaxis=dict(showticklabels=False))

            fig.add_trace(
                go.Scatterpolar(
                    name=row.å—è¨ªè€…,
                    r=row_normalized_list,
                    theta=features_closed,
                    fill="toself",
                    showlegend=False,
                ),
                row=subplot_row,
                col=subplot_col,
            )

        # Update layout to remove radial tick labels and adjust layout
        fig.update_layout(
            **layout_update, margin=dict(t=50, b=50, l=100, r=100), height=1000
        )
        fig.update_polars(radialaxis=dict(range=[0, 1]))

        return fig

    def _generate_single_chart(self, df, features, features_closed, MAX_VALUES):
        row_normalized = {col: df[col][0] / MAX_VALUES[col] for col in features}
        row_normalized_list = list(row_normalized.values()) + [
            list(row_normalized.values())[0]
        ]

        fig = px.line_polar(
            df,
            r=row_normalized_list,
            theta=features_closed,
        )
        fig.update_traces(fill="toself", showlegend=False)

        return fig

    def generate_distribution(self, df: pd.DataFrame, features: List[str]):
        dist_df = df.copy()
        dist_df = dist_df[dist_df["å…§å¤–éƒ¨"] == "å¤–éƒ¨"].reset_index(drop=True)
        for feature in features:
            num_bins = int(dist_df[feature].max() - dist_df[feature].min() + 1)

            fig = px.histogram(
                dist_df,
                x=feature,
                marginal="box",
                title=f"å¤–éƒ¨é—œéµTA vs å¤–éƒ¨éé—œéµçš„{feature}å¸¸æ…‹åˆ†ä½ˆ",
                nbins=num_bins,
                color="é—œéµTA",
                color_discrete_sequence=["red", "blue"],
            )

            fig.update_layout(
                xaxis=dict(tickmode="linear", tick0=dist_df[feature].min(), dtick=1)
            )

            fig.update_traces(opacity=0.75)
            st.plotly_chart(fig, use_container_width=True)
        st.markdown("### çµè«–")
        st.text("ä¾ç…§å…­å¤§ç‰¹è³ªåŠ ç¸½çµæœï¼Œå®šç¾©å‡ºåˆ¤åˆ¥é—œéµ TA çš„æ¨™æº–ç·šï¼Œç‚ºç¸½åˆ†18åˆ†ä»¥ä¸Šã€‚ï¼ˆæ»¿åˆ†23åˆ†ï¼‰")

    def generate_correlation_matrix(
        self,
        df: pd.DataFrame,
        features: List[str],
        title="å¤–éƒ¨è¨ªè«‡è€…å…§åœ¨ vs. å¤–åœ¨çš„ç‰¹è³ªç›¸é—œåº¦ (ç­‰ç´šç›¸é—œä¿‚æ•¸)",
        xaxis="å¤–åœ¨ç‰¹è³ª",
        yaxis="å…§åœ¨ç‰¹è³ª",
    ):
        corr_df = df.copy()
        corr_df = corr_df[corr_df["å…§å¤–éƒ¨"] == "å¤–éƒ¨"].reset_index(drop=True)
        corr_mx = corr_df[corr_features].corr(method="kendall")
        corr_mx = corr_mx[0:5][outside_features]
        fig = ff.create_annotated_heatmap(
            z=corr_mx.values,
            x=list(corr_mx.columns),
            y=list(corr_mx.index),
            annotation_text=corr_mx.round(2).values,
            colorscale="Viridis",
            showscale=True,
            hoverinfo="z",
        )
        fig.update_layout(
            title=title,
            xaxis=dict(title=xaxis, side="bottom"),
            yaxis=dict(title=yaxis),
        )
        st.plotly_chart(fig, use_container_width=True)
        st.markdown("_0.2ä»¥ä¸‹ä¸ç›¸é—œï¼Œ0.2 âˆ’ 0.39 æ˜¯å¼±ç›¸é—œï¼Œ 0.4 âˆ’ 0.59 æ˜¯ä¸­åº¦ç›¸é—œï¼Œ0.6 âˆ’ 0.79 æ˜¯å¼·ç›¸é—œã€‚_")
        st.markdown("### çµè«–")
        st.text("1. è‡ªæˆ‘èº«å¿ƒç…§é¡§èˆ‡æ¯å‘å…§åœ¨ç‰¹è³ªæœ‰é«˜åº¦ç›¸é—œæ€§ï¼Œæ‰€ä»¥å¾ˆé‡è¦çš„å¤–åœ¨æŒ‡æ¨™")
        st.text("2. é‡åŒ–æ±‚è·è€ƒé‡èˆ‡è§£æ±ºå•é¡Œæ„é¡˜å’ŒåŸºæœ¬æºé€šè¡¨é”æ˜¯é«˜ç›¸é—œ")
        st.text("3. å®¶äººæ”¯æŒç¨‹åº¦èˆ‡ç¾å‘å…§åœ¨ç‰¹è³ªæ˜¯ä¸­åº¦ç›¸é—œ")

    def generate_disability_histogram(self, df):
        my_df = df.copy()
        key_ta_df = my_df[my_df["é—œéµTA"] == "T"]
        nonkey_ta_df = my_df[my_df["é—œéµTA"] == "F"]

        key_ta_experience_distribution = key_ta_df["éšœåˆ¥"].value_counts()
        non_key_ta_experience_distribution = nonkey_ta_df["éšœåˆ¥"].value_counts()

        combined_data = pd.concat(
            [
                key_ta_experience_distribution.rename("æ˜¯"),
                non_key_ta_experience_distribution.rename("å¦"),
            ],
            axis=1,
        ).fillna(0)

        combined_data["Total"] = combined_data["æ˜¯"] + combined_data["å¦"]
        combined_data["Total"] = combined_data["Total"].astype(int)
        combined_data = combined_data.reset_index().rename(
            columns={"index": "Disability Type"}
        )
        combined_data.reset_index(inplace=True)
        combined_data.rename(columns={"index": "Experience Type"}, inplace=True)
        fig = px.bar(
            combined_data,
            x="éšœåˆ¥",
            y=["æ˜¯", "å¦"],
            barmode="stack",
            title="éšœåˆ¥åˆ†ä½ˆåœ–",
            labels={"value": "äººæ•¸", "variable": "é—œéµTA?"},
            color_discrete_sequence=["red", "blue"],
        )
        for i, total in enumerate(combined_data["Total"]):
            fig.add_annotation(
                x=combined_data["Experience Type"][i],
                y=total,
                text=str(total),
                showarrow=False,
                yshift=10,  # Adjust this value to position the annotation above the bar
            )
        st.plotly_chart(fig, use_container_width=True)

    def generate_education_histogram(self, df):
        my_df = df.copy()
        key_ta_df = my_df[my_df["é—œéµTA"] == "T"]
        nonkey_ta_df = my_df[my_df["é—œéµTA"] == "F"]

        key_ta_experience_distribution = (
            key_ta_df["å•å·å­¸æ­·"].str.split("ã€").explode().value_counts()
        )
        non_key_ta_experience_distribution = (
            nonkey_ta_df["å•å·å­¸æ­·"].str.split("ã€").explode().value_counts()
        )

        combined_data = pd.concat(
            [
                key_ta_experience_distribution.rename("æ˜¯"),
                non_key_ta_experience_distribution.rename("å¦"),
            ],
            axis=1,
        ).fillna(0)

        combined_data["Total"] = combined_data["æ˜¯"] + combined_data["å¦"]
        combined_data["Total"] = combined_data["Total"].astype(int)
        combined_data = combined_data.reset_index().rename(
            columns={"index": "Experience Type"}
        )
        combined_data.reset_index(inplace=True)
        combined_data.rename(columns={"index": "Experience Type"}, inplace=True)
        fig = px.bar(
            combined_data,
            x="å•å·å­¸æ­·",
            y=["æ˜¯", "å¦"],
            barmode="stack",
            title="å­¸æ­·åˆ†ä½ˆåœ–",
            labels={"value": "äººæ•¸", "variable": "é—œéµTA?"},
            color_discrete_sequence=["red", "blue"],
        )
        for i, total in enumerate(combined_data["Total"]):
            fig.add_annotation(
                x=combined_data["Experience Type"][i],
                y=total,
                text=str(total),
                showarrow=False,
                yshift=10,  # Adjust this value to position the annotation above the bar
            )
        st.plotly_chart(fig, use_container_width=True)

    def generate_job_consideration_histogram(self, df):
        my_df = df.copy()
        ta_df = my_df[my_df["é—œéµTA"] == "T"]
        nonta_df = my_df[my_df["é—œéµTA"] == "F"]
        jc_true = ta_df["æ±‚è·è€ƒé‡"].str.split("ã€").explode().str.strip()
        jc_false = nonta_df["æ±‚è·è€ƒé‡"].str.split("ã€").explode().str.strip()
        jc_counts_true = pd.Series(Counter(jc_true)).reset_index()
        jc_counts_false = pd.Series(Counter(jc_false)).reset_index()
        jc_counts_true.columns = ["æ±‚è·è€ƒé‡", "äººæ•¸"]
        jc_counts_false.columns = ["æ±‚è·è€ƒé‡", "äººæ•¸"]
        jc_counts_true["é—œéµTA"] = "æ˜¯"
        jc_counts_false["é—œéµTA"] = "å¦"
        combined_counts_with_key_TA = pd.concat([jc_counts_true, jc_counts_false])
        total_counts = (
            combined_counts_with_key_TA.groupby("æ±‚è·è€ƒé‡")["äººæ•¸"].sum().reset_index()
        )
        fig = px.bar(
            combined_counts_with_key_TA,
            x="æ±‚è·è€ƒé‡",
            y="äººæ•¸",
            color="é—œéµTA",
            title="æ±‚è·è€ƒé‡åˆ†ä½ˆåœ–",
            labels={"äººæ•¸": "äººæ•¸", "æ±‚è·è€ƒé‡": "æ±‚è·è€ƒé‡", "é—œéµTA": "é—œéµTA"},
            color_discrete_sequence=["red", "blue"],
        )

        # Add text annotations for total counts
        for i, row in total_counts.iterrows():
            fig.add_annotation(
                x=row["æ±‚è·è€ƒé‡"],
                y=row["äººæ•¸"],
                text=str(row["äººæ•¸"]),
                showarrow=True,
                font=dict(size=12, color="black"),
            )
        st.plotly_chart(fig, use_container_width=True)

    def generate_job_channel_histogram(self, df, title="å•å·æ±‚è·ç®¡é“"):
        my_df = df.copy()
        ta_df = my_df[my_df["é—œéµTA"] == "T"]
        nonta_df = my_df[my_df["é—œéµTA"] == "F"]
        # Count job considerations for both subsets
        jc_true = ta_df["å•å·æ±‚è·ç®¡é“"].str.split("ã€").explode().str.strip()
        jc_false = nonta_df["å•å·æ±‚è·ç®¡é“"].str.split("ã€").explode().str.strip()
        jc_counts_true = pd.Series(Counter(jc_true)).reset_index()
        jc_counts_false = pd.Series(Counter(jc_false)).reset_index()
        jc_counts_true.columns = ["å•å·æ±‚è·ç®¡é“", "äººæ•¸"]
        jc_counts_false.columns = ["å•å·æ±‚è·ç®¡é“", "äººæ•¸"]
        jc_counts_true["é—œéµTA"] = "æ˜¯"
        jc_counts_false["é—œéµTA"] = "å¦"
        combined_counts_with_key_TA = pd.concat([jc_counts_true, jc_counts_false])
        total_counts = (
            combined_counts_with_key_TA.groupby("å•å·æ±‚è·ç®¡é“")["äººæ•¸"].sum().reset_index()
        )

        fig = px.bar(
            combined_counts_with_key_TA,
            x="å•å·æ±‚è·ç®¡é“",
            y="äººæ•¸",
            color="é—œéµTA",
            title=title,
            labels={"äººæ•¸": "äººæ•¸", "å•å·æ±‚è·ç®¡é“": "å•å·æ±‚è·ç®¡é“", "é—œéµTA": "é—œéµTA"},
            color_discrete_sequence=["red", "blue"],
        )

        # Add text annotations for total counts
        for i, row in total_counts.iterrows():
            fig.add_annotation(
                x=row["å•å·æ±‚è·ç®¡é“"],
                y=row["äººæ•¸"],
                text=str(row["äººæ•¸"]),
                showarrow=True,
                font=dict(size=12, color="black"),
            )
        st.plotly_chart(fig, use_container_width=True)
        st.markdown("### çµè«–")
        st.text("1. ç„¡è«–æ˜¯æ±‚è·ç®¡é“ç¸½äººæ•¸(20äºº)ï¼Œä»¥åŠæ‹›å‹Ÿç®¡é“æœ‰æ•ˆæ€§(12äººï¼Œ60%)çš†ä»¥ç¶²è·¯äººåŠ›éŠ€è¡Œç‚ºæœ€é«˜")
        st.text("2. æ‹›å‹Ÿç®¡æ•ˆæ€§æ¬¡é«˜ç‚ºç¤¾ç¾¤è²¼æ–‡ï¼ˆ4äººï¼Œ57%ï¼‰")
        st.text("3. æ ¹æ“šå¯¦éš›è¨ªè«‡èˆ‡æ±‚è·ç®¡é“æ¯”å°å¾Œï¼Œç™¼ç¾é—œéµ TA ä¸¦éé›†ä¸­å­˜åœ¨ã€Œèˆ‡è©²éšœåˆ¥ç›´æ¥ç›¸é—œã€çš„å‚·å‹æ”¯æŒç¤¾ç¾¤æˆ–éç‡Ÿåˆ©çµ„ç¹”")
        st.text("4. ç›¸å°ä¾†èªªï¼Œä»–å€‘å¤šèšé›†æ–¼èˆˆè¶£ã€è‡ªæˆ‘æŒ‘æˆ°å°å‘çš„ç§å¯†ç¤¾ç¾¤ï¼Œä¾‹ï¼šè¼ªæ¤…å¤¢å…¬åœ’ç¾¤çµ„")
        st.text("5. æœªä¾†å¯å¼·åŒ–é€£çµåŒæ€§è³ªç¤¾ç¾¤ï¼Œæå‡é—œéµTAè§¸åŠç‡ï¼Œä¾‹ï¼šèº«å¿ƒéšœç¤™æ½›æ°´å”æœƒ")


# dashboard title
st.title(":potable_water: :blue[è‹¥æ°´]èº«éšœå°±æ¥­è³‡æ–™åˆ†æ")
st.markdown("ã€_å‰µé€ å¤šå…ƒå…±ï»¿èç’°å¢ƒæ˜¯ç‚ºäº†æ¯ä¸€å€‹äºº_ã€ï¼Œæˆ‘å€‘å¸Œæœ›é€éå•†æ¥­åŠ›é‡ï¼Œå”åŠ©ä¼æ¥­å’Œèº«éšœäººæ‰æœ‰æ•ˆéŠœæ¥ï¼Œæ”¹å–„èº«éšœå°±æ¥­å•é¡Œï¼")


scores_df = read_data(dataset_url)

placeholder = st.empty()
with placeholder.container():
    fig_col1, fig_col2, fig_col3 = st.columns(3, gap="large")
    with fig_col1:
        st.header(":dart: å®šä½")
        option = st.selectbox(
            "è¦–è¦ºåŒ–å…­å¤§ç‰¹è³ª",
            ("å¤–éƒ¨é—œéµTAçš„ç‰¹è³ªå¸¸æ…‹åˆ†ä½ˆ", "å…§å¤–éƒ¨é—œéµTAçš„ç‰¹è³ªé›·é”åœ–", "å…§å¤–éƒ¨é—œéµTAçš„ç‰¹è³ªä¸­é–“å€¼"),
            index=None,
            placeholder="é¸æ“‡è¦–è¦ºåŒ–åœ–è¡¨",
        )
        radar_features = ["å·¥ä½œæ„é¡˜å’Œå‹•æ©Ÿ", "å­¸ç¿’å‹•åŠ›", "åŸºæœ¬æºé€šè¡¨é”", "å·¥ä½œè²¬ä»»æ„Ÿ", "è§£æ±ºå•é¡Œæ„é¡˜", "è‡ªæˆ‘èº«å¿ƒç…§é¡§"]
        if option == "å¤–éƒ¨é—œéµTAçš„ç‰¹è³ªå¸¸æ…‹åˆ†ä½ˆ":
            distribution = Visualization("distribution", scores_df, radar_features)
        if option == "å…§å¤–éƒ¨é—œéµTAçš„ç‰¹è³ªé›·é”åœ–":
            filter_col1, filter_col2 = st.columns(2)
            with filter_col1:
                inside_outside_filter = st.selectbox(
                    "é¸æ“‡å…§å¤–éƒ¨", pd.unique(scores_df["å…§å¤–éƒ¨"])
                )
            if inside_outside_filter == "å¤–éƒ¨":
                with filter_col2:
                    ta_filter = st.selectbox("é¸æ“‡é—œéµTA", pd.unique(scores_df["é—œéµTA"]))
                radar_df = scores_df.copy()
                radar_df = radar_df[
                    radar_df["å…§å¤–éƒ¨"] == inside_outside_filter
                ].reset_index(drop=True)
                radar_df = radar_df[radar_df["é—œéµTA"] == ta_filter].reset_index(
                    drop=True
                )

                radar_charts = Visualization(
                    "personality",
                    radar_df,
                    radar_features,
                    2,
                )
            else:
                radar_df = scores_df.copy()
                radar_df = radar_df[
                    radar_df["å…§å¤–éƒ¨"] == inside_outside_filter
                ].reset_index(drop=True)
                radar_charts = Visualization(
                    "personality",
                    radar_df,
                    radar_features,
                    2,
                )
        if option == "å…§å¤–éƒ¨é—œéµTAçš„ç‰¹è³ªä¸­é–“å€¼":
            median_radar_chart = Visualization("median", scores_df, radar_features)

    with fig_col2:
        st.header(":pinching_hand: ç¯©é¸")
        option = st.selectbox(
            "è¦–è¦ºåŒ–å»ºæ¨¡èˆ‡ç‰¹è³ªç¯©é¸",
            (
                "ç‰¹è³ªç›¸é—œçŸ©é™£",
                "åˆ©ç”¨ç‰¹è³ªå»ºæ¨¡é æ¸¬é—œéµTA",
            ),
            index=None,
            placeholder="é¸æ“‡è¦–è¦ºåŒ–åœ–è¡¨",
        )

        if option == "ç‰¹è³ªç›¸é—œçŸ©é™£":
            corr_features = inside_features + outside_features
            correlation_matrix = Visualization("correlation", scores_df, corr_features)

        if option == "åˆ©ç”¨ç‰¹è³ªå»ºæ¨¡é æ¸¬é—œéµTA":
            pass

    with fig_col3:
        st.header(":books: ç®¡é“")
        option = st.selectbox(
            "è¦–è¦ºåŒ–æ±‚è·ç®¡é“èˆ‡è€ƒé‡",
            (
                "è¨ªè«‡è€…å•å·å­¸æ­·",
                "è¨ªè«‡è€…éšœåˆ¥åˆ†æ",
                "è¨ªè«‡è€…æ±‚è·è€ƒé‡",
                "å•å·æ±‚è·ç®¡é“",
            ),
            index=None,
            placeholder="é¸æ“‡è¦–è¦ºåŒ–åœ–è¡¨",
        )
        if option == "è¨ªè«‡è€…å•å·å­¸æ­·":
            education_dist = Visualization("education", scores_df)
        if option == "è¨ªè«‡è€…éšœåˆ¥åˆ†æ":
            disability_types = Visualization("disability", scores_df)
        if option == "è¨ªè«‡è€…æ±‚è·è€ƒé‡":
            job_consideration = Visualization("job_consideration", scores_df)
        if option == "å•å·æ±‚è·ç®¡é“":
            job_channel = Visualization("job_channel", scores_df)
